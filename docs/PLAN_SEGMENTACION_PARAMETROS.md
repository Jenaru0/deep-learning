# üî¨ PLAN DETALLADO: An√°lisis de Par√°metros Estructurales de Fisuras

**Fecha:** 10 de octubre, 2025  
**Objetivo:** Implementar an√°lisis cuantitativo de fisuras (ancho, orientaci√≥n, profundidad)  
**M√©todo:** Segmentaci√≥n sem√°ntica con U-Net sobre dataset CRACK500

---

## üìä AN√ÅLISIS DE VIABILIDAD

### ‚úÖ **LO QUE TENEMOS:**

#### 1. **Dataset CRACK500 - Listo para Segmentaci√≥n**

```
‚úÖ 3,806 im√°genes JPG (640x360 pixels)
‚úÖ 3,364 m√°scaras PNG (ground truth binario)
‚úÖ ~88% de im√°genes tienen m√°scara asociada
‚úÖ M√°scaras binarias: [False=fondo, True=fisura]
‚úÖ Densidad promedio de fisura: ~10% por imagen
‚úÖ Ya est√° descargado y organizado
```

#### 2. **Infraestructura Existente**

```
‚úÖ Entorno Python configurado con TensorFlow 2.17.0
‚úÖ GPU RTX 2050 optimizada (Mixed Precision + XLA)
‚úÖ Scripts de entrenamiento modulares y reutilizables
‚úÖ Pipeline de evaluaci√≥n con visualizaciones
‚úÖ Sistema de callbacks (early stopping, LR reduction)
```

#### 3. **Conocimiento del Equipo**

```
‚úÖ Experiencia con Transfer Learning (MobileNetV2)
‚úÖ Manejo de data augmentation
‚úÖ Optimizaci√≥n GPU (2.5x speed-up demostrado)
‚úÖ Evaluaci√≥n con m√©tricas avanzadas (IoU, Dice)
‚úÖ Interfaz web funcional (Streamlit)
```

---

## üéØ OBJETIVOS ESPEC√çFICOS

### **M√≥dulo 1: Segmentaci√≥n Sem√°ntica (Base)**

Entrenar modelo U-Net para **detectar p√≠xeles de fisuras**

**Entradas:** Imagen RGB 256x256  
**Salidas:** M√°scara binaria 256x256 (0=fondo, 1=fisura)  
**M√©trica principal:** IoU (Intersection over Union) > 0.75

### **M√≥dulo 2: Medici√≥n de Ancho**

Calcular **ancho promedio y m√°ximo** de fisuras en mil√≠metros

**M√©todo:**

1. Esqueletonizar m√°scara predicha (morfolog√≠a)
2. Calcular distancia de cada p√≠xel al borde de la fisura
3. Promediar distancias en la m√°scara
4. Convertir p√≠xeles ‚Üí mm con calibraci√≥n

**Salida:** `ancho_promedio=2.3mm, ancho_max=5.1mm`

### **M√≥dulo 3: Detecci√≥n de Orientaci√≥n**

Clasificar fisuras en **Horizontal / Vertical / Diagonal**

**M√©todo:**

1. Aplicar transformada de Hough sobre m√°scara
2. Detectar l√≠neas principales
3. Calcular √°ngulo dominante
4. Clasificar:
   - H: 0¬∞-30¬∞ o 150¬∞-180¬∞
   - V: 60¬∞-120¬∞
   - D: 30¬∞-60¬∞ o 120¬∞-150¬∞

**Salida:** `orientacion='Diagonal', angulo=45¬∞`

### **M√≥dulo 4: Estimaci√≥n de Profundidad (Proxy)**

Estimar **profundidad relativa** basado en intensidad de p√≠xeles

**M√©todo (heur√≠stico):**

1. Analizar intensidad promedio en regi√≥n de fisura
2. Fisuras oscuras = profundas
3. Fisuras claras = superficiales
4. Clasificar: Superficial / Moderada / Profunda

**Limitaci√≥n:** Sin datos de profundidad real, solo proxy visual  
**Salida:** `profundidad='Moderada', confianza=0.7`

---

## üìê ARQUITECTURA T√âCNICA

### **Modelo de Segmentaci√≥n: U-Net**

```
Encoder (Contracting Path):
  Input: 256x256x3
  ‚îú‚îÄ Conv2D(64) + ReLU + Conv2D(64) + ReLU ‚Üí MaxPool ‚Üí 128x128
  ‚îú‚îÄ Conv2D(128) + ReLU + Conv2D(128) + ReLU ‚Üí MaxPool ‚Üí 64x64
  ‚îú‚îÄ Conv2D(256) + ReLU + Conv2D(256) + ReLU ‚Üí MaxPool ‚Üí 32x32
  ‚îî‚îÄ Conv2D(512) + ReLU + Conv2D(512) + ReLU ‚Üí MaxPool ‚Üí 16x16 (bottleneck)

Decoder (Expanding Path):
  ‚îú‚îÄ UpSampling + Conv2D(256) + Concatenate[skip] ‚Üí 32x32
  ‚îú‚îÄ UpSampling + Conv2D(128) + Concatenate[skip] ‚Üí 64x64
  ‚îú‚îÄ UpSampling + Conv2D(64) + Concatenate[skip] ‚Üí 128x128
  ‚îî‚îÄ UpSampling + Conv2D(32) + Concatenate[skip] ‚Üí 256x256

Output: Conv2D(1, activation='sigmoid') ‚Üí 256x256x1 (m√°scara)

Par√°metros: ~7.7M (vs 2.2M del MobileNetV2)
Loss: Binary Crossentropy + Dice Loss (combinado)
Optimizer: Adam, LR=1e-4
```

**¬øPor qu√© U-Net?**

- ‚úÖ Est√°ndar de oro para segmentaci√≥n m√©dica/industrial
- ‚úÖ Skip connections preservan detalles finos (fisuras delgadas)
- ‚úÖ Funciona bien con pocos datos (~3K im√°genes)
- ‚úÖ Arquitectura probada en detecci√≥n de grietas

---

## üì¶ RECURSOS NECESARIOS

### **Datos**

```
‚úÖ YA DISPONIBLE: 3,364 pares imagen-m√°scara
üìä Split propuesto:
   - Train: 2,691 (80%)
   - Val: 336 (10%)
   - Test: 337 (10%)
```

### **Computaci√≥n**

```
‚úÖ GPU: RTX 2050 (4GB VRAM)
   - U-Net (256x256, batch=8): ~3.2GB VRAM ‚úÖ CABE
   - Mixed Precision: ~2.1GB VRAM ‚úÖ √ìPTIMO

‚è±Ô∏è Tiempo estimado de entrenamiento:
   - Sin optimizaci√≥n: ~4-5 horas (50 epochs)
   - Con Mixed Precision + XLA: ~2-2.5 horas ‚úÖ
```

### **Software**

```
‚úÖ TensorFlow 2.17.0 (instalado)
‚úÖ OpenCV para procesamiento morfol√≥gico
‚úÖ scikit-image para esqueletonizaci√≥n
‚úÖ scipy para transformada de Hough
```

---

## üóìÔ∏è PLAN DE IMPLEMENTACI√ìN

### **FASE 1: Preparaci√≥n de Datos (D√≠a 1 - 4 horas)**

**Tarea 1.1: Organizar dataset para segmentaci√≥n**

```bash
datos/procesados/segmentacion/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/  # 2,691 JPG
‚îÇ   ‚îî‚îÄ‚îÄ masks/   # 2,691 PNG
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ images/  # 336 JPG
‚îÇ   ‚îî‚îÄ‚îÄ masks/   # 336 PNG
‚îî‚îÄ‚îÄ test/
    ‚îú‚îÄ‚îÄ images/  # 337 JPG
    ‚îî‚îÄ‚îÄ masks/   # 337 PNG
```

**Script:** `scripts/preprocesamiento/preparar_crack500.py`

- Leer pares v√°lidos imagen-m√°scara
- Dividir estratificadamente (80/10/10)
- Copiar a estructura organizada
- Validar integridad (SHA256)

**Tarea 1.2: Pipeline de carga con tf.data**

```python
def load_segmentation_data():
    # Data augmentation:
    - Random flip (horizontal/vertical)
    - Random rotation (¬±15¬∞)
    - Random brightness (¬±20%)
    - Elastic deformation (para fisuras)

    # Normalizaci√≥n:
    - Im√°genes: [0, 255] ‚Üí [0, 1]
    - M√°scaras: {False, True} ‚Üí {0, 1}
```

---

### **FASE 2: Entrenamiento del Modelo U-Net (D√≠a 2 - 3 horas)**

**Tarea 2.1: Implementar arquitectura U-Net**

**Script:** `scripts/entrenamiento/entrenar_segmentacion.py`

```python
def construir_unet(input_size=(256, 256, 3)):
    inputs = Input(input_size)

    # Encoder
    c1 = conv_block(inputs, 64)
    p1 = MaxPooling2D()(c1)

    c2 = conv_block(p1, 128)
    p2 = MaxPooling2D()(c2)

    c3 = conv_block(p2, 256)
    p3 = MaxPooling2D()(c3)

    c4 = conv_block(p3, 512)
    p4 = MaxPooling2D()(c4)

    # Bottleneck
    c5 = conv_block(p4, 1024)

    # Decoder con skip connections
    u6 = UpSampling2D()(c5)
    u6 = Concatenate()([u6, c4])
    c6 = conv_block(u6, 512)

    u7 = UpSampling2D()(c6)
    u7 = Concatenate()([u7, c3])
    c7 = conv_block(u7, 256)

    u8 = UpSampling2D()(c7)
    u8 = Concatenate()([u8, c2])
    c8 = conv_block(u8, 128)

    u9 = UpSampling2D()(c8)
    u9 = Concatenate()([u9, c1])
    c9 = conv_block(u9, 64)

    # Output
    outputs = Conv2D(1, 1, activation='sigmoid')(c9)

    model = Model(inputs, outputs)
    return model
```

**Tarea 2.2: Loss function combinada**

```python
def combined_loss(y_true, y_pred):
    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)
    dice = dice_loss(y_true, y_pred)
    return 0.5 * bce + 0.5 * dice

def dice_loss(y_true, y_pred):
    numerator = 2 * tf.reduce_sum(y_true * y_pred)
    denominator = tf.reduce_sum(y_true + y_pred)
    return 1 - (numerator + 1) / (denominator + 1)
```

**Tarea 2.3: Configuraci√≥n de entrenamiento**

```python
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss=combined_loss,
    metrics=['accuracy', iou_metric, dice_coefficient]
)

callbacks = [
    ModelCheckpoint('best_unet.keras', save_best_only=True),
    EarlyStopping(patience=10, restore_best_weights=True),
    ReduceLROnPlateau(factor=0.5, patience=5)
]

# Optimizaciones GPU
tf.config.optimizer.set_jit(True)  # XLA
policy = tf.keras.mixed_precision.Policy('mixed_float16')
```

**M√©tricas de evaluaci√≥n:**

- **IoU (Intersection over Union):** > 0.75 objetivo
- **Dice Coefficient:** > 0.85 objetivo
- **Pixel Accuracy:** > 95% objetivo
- **Precision/Recall** para p√≠xeles de fisura

---

### **FASE 3: Post-procesamiento y Mediciones (D√≠a 3 - 4 horas)**

**Tarea 3.1: Medici√≥n de ancho**

**Script:** `scripts/analisis/medir_parametros.py`

```python
import cv2
from skimage.morphology import skeletonize
from scipy.ndimage import distance_transform_edt

def medir_ancho_fisura(mask, pixels_per_mm=10):
    """
    Mide el ancho de fisura en la m√°scara.

    Args:
        mask: M√°scara binaria (0=fondo, 1=fisura)
        pixels_per_mm: Factor de calibraci√≥n (depende de distancia de c√°mara)

    Returns:
        dict: {ancho_promedio_mm, ancho_max_mm, ancho_min_mm}
    """
    # 1. Esqueletonizar para encontrar eje central
    skeleton = skeletonize(mask > 0.5)

    # 2. Calcular distancia de cada p√≠xel al borde
    distance_map = distance_transform_edt(mask > 0.5)

    # 3. Extraer anchos en el esqueleto
    anchos_pixels = distance_map[skeleton] * 2  # *2 porque distance es radio

    # 4. Convertir a mm
    ancho_prom_mm = np.mean(anchos_pixels) / pixels_per_mm
    ancho_max_mm = np.max(anchos_pixels) / pixels_per_mm
    ancho_min_mm = np.min(anchos_pixels) / pixels_per_mm

    return {
        'ancho_promedio_mm': round(ancho_prom_mm, 2),
        'ancho_maximo_mm': round(ancho_max_mm, 2),
        'ancho_minimo_mm': round(ancho_min_mm, 2),
        'area_total_mm2': round(np.sum(mask > 0.5) / (pixels_per_mm**2), 2)
    }
```

**Tarea 3.2: Detecci√≥n de orientaci√≥n**

```python
def detectar_orientacion(mask):
    """
    Detecta la orientaci√≥n dominante de la fisura.

    Returns:
        dict: {orientacion, angulo, confianza}
    """
    # 1. Detecci√≥n de bordes
    edges = cv2.Canny((mask * 255).astype(np.uint8), 50, 150)

    # 2. Transformada de Hough para detectar l√≠neas
    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)

    if lines is None:
        return {'orientacion': 'Indefinida', 'angulo': None, 'confianza': 0.0}

    # 3. Calcular √°ngulo dominante
    angulos = []
    for line in lines:
        rho, theta = line[0]
        angulo_deg = np.degrees(theta)
        angulos.append(angulo_deg)

    angulo_dominante = np.median(angulos)

    # 4. Clasificar orientaci√≥n
    if (0 <= angulo_dominante <= 30) or (150 <= angulo_dominante <= 180):
        orientacion = 'Horizontal'
    elif 60 <= angulo_dominante <= 120:
        orientacion = 'Vertical'
    else:
        orientacion = 'Diagonal'

    # 5. Calcular confianza (clustering de √°ngulos)
    std_angulos = np.std(angulos)
    confianza = max(0, 1 - std_angulos / 90)  # Menor std = mayor confianza

    return {
        'orientacion': orientacion,
        'angulo': round(angulo_dominante, 1),
        'confianza': round(confianza, 2)
    }
```

**Tarea 3.3: Estimaci√≥n de profundidad (proxy visual)**

```python
def estimar_profundidad(imagen, mask):
    """
    Estima profundidad relativa bas√°ndose en intensidad de p√≠xeles.

    LIMITACI√ìN: Es un proxy visual, NO mide profundidad real.
    Se requerir√≠a visi√≥n est√©reo o sensor de profundidad para precisi√≥n.

    Returns:
        dict: {profundidad, intensidad_promedio, confianza}
    """
    # 1. Extraer regi√≥n de fisura
    fisura_region = imagen[mask > 0.5]

    if len(fisura_region) == 0:
        return {'profundidad': 'Desconocida', 'confianza': 0.0}

    # 2. Calcular intensidad promedio en escala de grises
    gray = cv2.cvtColor(imagen, cv2.COLOR_RGB2GRAY)
    intensidad_fisura = np.mean(gray[mask > 0.5])
    intensidad_fondo = np.mean(gray[mask <= 0.5])

    # 3. Contraste relativo
    contraste = abs(intensidad_fisura - intensidad_fondo)

    # 4. Clasificaci√≥n heur√≠stica
    if intensidad_fisura < 80 and contraste > 50:
        profundidad = 'Profunda'
        confianza = 0.7
    elif intensidad_fisura < 120:
        profundidad = 'Moderada'
        confianza = 0.6
    else:
        profundidad = 'Superficial'
        confianza = 0.5

    return {
        'profundidad': profundidad,
        'intensidad_promedio': round(intensidad_fisura, 1),
        'contraste': round(contraste, 1),
        'confianza': confianza
    }
```

---

### **FASE 4: Integraci√≥n con Interfaz Web (D√≠a 4 - 3 horas)**

**Tarea 4.1: Actualizar app.py con modo segmentaci√≥n**

```python
# En app_web/app.py a√±adir:

@st.cache_resource
def cargar_modelo_segmentacion():
    """Carga modelo U-Net para segmentaci√≥n."""
    modelo_path = Path(MODELOS_DIR) / "segmentacion" / "best_unet.keras"
    if modelo_path.exists():
        return tf.keras.models.load_model(modelo_path, compile=False)
    return None

def analizar_parametros_fisura(imagen, modelo_det, modelo_seg):
    """
    An√°lisis completo de fisura.

    Returns:
        dict: {
            tiene_fisura: bool,
            confianza_deteccion: float,
            mascara: np.array,
            ancho_mm: float,
            orientacion: str,
            profundidad: str,
            visualizacion: PIL.Image
        }
    """
    # 1. Detecci√≥n binaria
    tiene_fisura, conf_det, _ = predecir(modelo_det, imagen)

    if not tiene_fisura or modelo_seg is None:
        return {'tiene_fisura': False}

    # 2. Segmentaci√≥n
    img_prep = preprocesar_para_segmentacion(imagen)
    mascara = modelo_seg.predict(img_prep, verbose=0)[0, :, :, 0]

    # 3. An√°lisis de par√°metros
    ancho_info = medir_ancho_fisura(mascara)
    orient_info = detectar_orientacion(mascara)
    prof_info = estimar_profundidad(np.array(imagen), mascara)

    # 4. Visualizaci√≥n
    overlay = crear_overlay_mascara(imagen, mascara)

    return {
        'tiene_fisura': True,
        'confianza_deteccion': conf_det,
        'mascara': mascara,
        'ancho_promedio_mm': ancho_info['ancho_promedio_mm'],
        'ancho_maximo_mm': ancho_info['ancho_maximo_mm'],
        'orientacion': orient_info['orientacion'],
        'angulo': orient_info['angulo'],
        'profundidad': prof_info['profundidad'],
        'visualizacion': overlay
    }
```

**Tarea 4.2: Dise√±o de panel de resultados**

```python
# En la interfaz Streamlit mostrar:

if resultado['tiene_fisura']:
    st.success("‚úÖ FISURA DETECTADA - An√°lisis Detallado")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "Ancho Promedio",
            f"{resultado['ancho_promedio_mm']} mm",
            f"Max: {resultado['ancho_maximo_mm']} mm"
        )

    with col2:
        st.metric(
            "Orientaci√≥n",
            resultado['orientacion'],
            f"{resultado['angulo']}¬∞"
        )

    with col3:
        st.metric(
            "Profundidad (Est.)",
            resultado['profundidad'],
            delta=None
        )

    # Visualizaci√≥n de m√°scara
    st.image(resultado['visualizacion'], caption="Segmentaci√≥n de Fisura")
```

---

## ‚è±Ô∏è CRONOGRAMA COMPLETO

| D√≠a       | Fase          | Tareas                                | Tiempo       | Entregable                     |
| --------- | ------------- | ------------------------------------- | ------------ | ------------------------------ |
| **1**     | Preparaci√≥n   | Organizar CRACK500, pipeline de carga | 4h           | `preparar_crack500.py` ‚úÖ      |
| **2**     | Entrenamiento | Implementar U-Net, entrenar modelo    | 3h           | `modelo_segmentacion.keras` ‚úÖ |
| **3**     | An√°lisis      | Medici√≥n de par√°metros, validaci√≥n    | 4h           | `medir_parametros.py` ‚úÖ       |
| **4**     | Integraci√≥n   | Actualizar interfaz web, testing      | 3h           | App web actualizada ‚úÖ         |
| **TOTAL** |               |                                       | **14 horas** | Sistema completo üéâ            |

---

## üìä M√âTRICAS DE √âXITO

### **Modelo de Segmentaci√≥n**

- ‚úÖ IoU > 0.75 en test set
- ‚úÖ Dice Coefficient > 0.85
- ‚úÖ Tiempo de inferencia < 100ms por imagen

### **Mediciones de Par√°metros**

- ‚úÖ Ancho: error < 0.5mm vs medici√≥n manual
- ‚úÖ Orientaci√≥n: concordancia > 90%
- ‚úÖ Profundidad: clasificaci√≥n correcta > 70% (limitado por falta de ground truth)

### **Interfaz de Usuario**

- ‚úÖ An√°lisis completo en < 2 segundos
- ‚úÖ Visualizaci√≥n clara de m√°scara
- ‚úÖ M√©tricas presentadas de forma comprensible

---

## üöß LIMITACIONES Y CONSIDERACIONES

### **Limitaciones T√©cnicas**

1. **Calibraci√≥n de Escala**

   - ‚ö†Ô∏è `pixels_per_mm` depende de distancia de c√°mara
   - Soluci√≥n: Incluir objeto de referencia (moneda, regla) o EXIF metadata
   - Por defecto: asumir 10 pixels/mm (ajustable)

2. **Profundidad es Proxy Visual**

   - ‚ö†Ô∏è NO es medici√≥n real de profundidad
   - ‚ö†Ô∏è Requerir√≠a visi√≥n est√©reo o sensor LiDAR
   - ‚ö†Ô∏è Solo clasifica: superficial/moderada/profunda bas√°ndose en intensidad
   - Documentar claramente esta limitaci√≥n

3. **Dataset de Pavimento vs Estructuras**

   - ‚ö†Ô∏è CRACK500 es principalmente pavimento
   - ‚ö†Ô∏è Puede no generalizar perfectamente a muros/decks
   - Soluci√≥n: Fine-tuning con im√°genes de SDNET2018 (si se anotan m√°scaras)

4. **Evoluci√≥n Temporal**
   - ‚ùå No implementable sin dataset longitudinal
   - ‚ùå Requerir√≠a im√°genes del mismo lugar en diferentes fechas
   - Postponer para trabajo futuro

### **Requerimientos de Datos Adicionales**

Para mejorar precisi√≥n:

- Ground truth de anchos reales (mediciones manuales)
- Im√°genes con escala conocida (regla en foto)
- Anotaciones de profundidad por expertos

---

## ‚úÖ VIABILIDAD: **ALTA (95%)**

### **Resumen Ejecutivo:**

**¬øSE PUEDE HACER?** ‚Üí **S√ç ‚úÖ**

**¬øCON LO QUE TENEMOS?** ‚Üí **S√ç ‚úÖ**

**¬øEN CU√ÅNTO TIEMPO?** ‚Üí **14 horas (2 d√≠as laborales)** ‚úÖ

**¬øQU√â OBTENDREMOS?**

1. ‚úÖ **Segmentaci√≥n precisa** de fisuras pixel por pixel
2. ‚úÖ **Medici√≥n de ancho** en mil√≠metros (con calibraci√≥n)
3. ‚úÖ **Clasificaci√≥n de orientaci√≥n** (H/V/D) con √°ngulo
4. ‚úÖ **Estimaci√≥n de profundidad** (proxy visual, limitado)
5. ‚úÖ **Interfaz web actualizada** con an√°lisis completo
6. ‚úÖ **Visualizaciones** de m√°scaras superpuestas

**¬øQU√â NO PODREMOS HACER (todav√≠a)?**

1. ‚ùå **An√°lisis de evoluci√≥n temporal** (falta dataset longitudinal)
2. ‚ùå **Medici√≥n de profundidad real** (requiere hardware especializado)
3. ‚ùå **Clasificaci√≥n de severidad estructural** (requiere expertos)

---

## üéØ RECOMENDACI√ìN FINAL

### **Proceder con Implementaci√≥n: S√ç ‚úÖ**

**Razones:**

1. **Dataset disponible y adecuado** (3,364 pares imagen-m√°scara)
2. **Infraestructura probada** (GPU optimizada, 2.5x speed-up)
3. **Arquitectura est√°ndar** (U-Net es estado del arte)
4. **Tiempo razonable** (14 horas distribuidas en 2-4 d√≠as)
5. **Alto impacto acad√©mico** (pasa de clasificaci√≥n a medici√≥n cuantitativa)

**Pr√≥ximo Paso:**

¬øQuieres que empiece con la **Fase 1 (Preparaci√≥n de Datos)** creando el script `scripts/preprocesamiento/preparar_crack500.py`?

Esto organizar√° el dataset CRACK500 en la estructura train/val/test necesaria para entrenar U-Net.

---

**Autor:** GitHub Copilot  
**Revisi√≥n:** Pendiente por usuario  
**Estado:** Plan completo - Listo para ejecuci√≥n ‚úÖ
