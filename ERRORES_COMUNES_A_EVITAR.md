# ‚ö†Ô∏è ERRORES COMUNES A EVITAR - Gu√≠a de Prevenci√≥n

---

## üö´ CATEGOR√çA 1: GESTI√ìN DE DATOS

### ‚ùå Error #1: Modificar datasets originales

**Problema:** Copiar, mover o editar archivos en `datasets/SDNET2018` o `datasets/CRACK500`  
**Impacto:** P√©rdida de datos originales, imposibilidad de replicar experimentos  
**Soluci√≥n:** SIEMPRE trabajar en `datos/procesados/`. Los originales son SAGRADOS.

### ‚ùå Error #2: No validar integridad de datos

**Problema:** Asumir que todos los archivos est√°n completos sin verificar  
**Impacto:** Errores silenciosos durante entrenamiento, resultados inconsistentes  
**Soluci√≥n:** Verificar conteos, formatos y que no haya archivos corruptos ANTES de entrenar

### ‚ùå Error #3: Mezclar splits train/val/test

**Problema:** Usar mismas im√°genes en entrenamiento y evaluaci√≥n  
**Impacto:** Data leakage = m√©tricas infladas = resultados inv√°lidos  
**Soluci√≥n:** Dividir UNA VEZ con semilla fija, documentar splits, nunca re-mezclar

### ‚ùå Error #4: No balancear clases

**Problema:** Entrenar con 85% negativos / 15% positivos sin ajustes  
**Impacto:** Modelo aprende a predecir "sin fisura" siempre = 85% accuracy in√∫til  
**Soluci√≥n:** Usar `class_weight`, data augmentation en minoritaria, o undersampling controlado

---

## üö´ CATEGOR√çA 2: CONFIGURACI√ìN Y C√ìDIGO

### ‚ùå Error #5: Rutas relativas inconsistentes

**Problema:** Usar `../datos/train` en un script, `./datos/train` en otro  
**Impacto:** Scripts fallan seg√∫n desde d√≥nde se ejecuten  
**Soluci√≥n:** TODAS las rutas absolutas definidas en `config.py`, importar ese m√≥dulo siempre

### ‚ùå Error #6: No fijar semilla aleatoria

**Problema:** Cada ejecuci√≥n da resultados distintos  
**Impacto:** Imposible reproducir experimentos, comparaciones inv√°lidas  
**Soluci√≥n:** `RANDOM_SEED = 42` en config.py, aplicar en NumPy, TensorFlow, Python random

### ‚ùå Error #7: Hardcodear valores

**Problema:** Escribir `epochs=50` en 10 lugares distintos del c√≥digo  
**Impacto:** Cambiar un par√°metro requiere editar m√∫ltiples archivos = errores  
**Soluci√≥n:** Centralizar TODOS los par√°metros en `config.py`

### ‚ùå Error #8: No versionar modelos

**Problema:** Sobrescribir `modelo.h5` cada vez que entrenas  
**Impacto:** Pierdes versiones anteriores, no puedes comparar  
**Soluci√≥n:** Guardar con nombres descriptivos: `modelo_deteccion_v1_acc_0.92.h5`

---

## üö´ CATEGOR√çA 3: ENTRENAMIENTO

### ‚ùå Error #9: No usar callbacks

**Problema:** Dejar entrenar 50 epochs sin early stopping ni guardado de mejor modelo  
**Impacto:** Overfitting, p√©rdida de mejor versi√≥n, tiempo desperdiciado  
**Soluci√≥n:** Usar `EarlyStopping`, `ModelCheckpoint`, `ReduceLROnPlateau`

### ‚ùå Error #10: Entrenar desde cero modelos grandes

**Problema:** Inicializar ResNet50 aleatoriamente en lugar de usar pesos ImageNet  
**Impacto:** 10x m√°s epochs necesarios, peores resultados  
**Soluci√≥n:** SIEMPRE usar `weights='imagenet'` en transfer learning

### ‚ùå Error #11: No validar durante entrenamiento

**Problema:** Solo mirar loss de entrenamiento, ignorar validaci√≥n  
**Impacto:** No detectas overfitting hasta el final  
**Soluci√≥n:** Monitorear `val_loss` y `val_accuracy` cada epoch

### ‚ùå Error #12: Batch size muy grande o muy peque√±o

**Problema:** Usar batch=256 en GPU de 4GB, o batch=2 en GPU de 24GB  
**Impacto:** OOM error o desperdicio de recursos  
**Soluci√≥n:** Empezar con batch=32, ajustar seg√∫n memoria disponible

---

## üö´ CATEGOR√çA 4: EVALUACI√ìN

### ‚ùå Error #13: Evaluar solo en accuracy

**Problema:** Reportar "95% accuracy" sin precision/recall en dataset desbalanceado  
**Impacto:** M√©trica enga√±osa, modelo in√∫til para clase minoritaria  
**Soluci√≥n:** Reportar precision, recall, F1, confusion matrix, ROC-AUC

### ‚ùå Error #14: No hacer an√°lisis cualitativo

**Problema:** Solo mostrar n√∫meros, sin casos visuales de aciertos/fallos  
**Impacto:** Tesis sin profundidad, no entiendes errores del modelo  
**Soluci√≥n:** Documentar 10+ casos cr√≠ticos con im√°genes y explicaciones

### ‚ùå Error #15: Comparar sin estandarizar test set

**Problema:** Comparar tu modelo en CRACK500 vs baseline en otro dataset  
**Impacto:** Comparaci√≥n inv√°lida, resultados no comparables  
**Soluci√≥n:** Entrenar TODOS los modelos en mismo train, evaluar en MISMO test

### ‚ùå Error #16: No validar con experto humano

**Problema:** Asumir que IoU=0.85 significa "sistema √∫til"  
**Impacto:** Falta evidencia de aplicabilidad pr√°ctica  
**Soluci√≥n:** Validar 50 casos con ingeniero civil, calcular Cohen's Kappa

---

## üö´ CATEGOR√çA 5: DOCUMENTACI√ìN

### ‚ùå Error #17: No llevar logs de experimentos

**Problema:** Entrenar 20 modelos, perder track de cu√°l fue el mejor y por qu√©  
**Impacto:** No puedes justificar decisiones en la tesis  
**Soluci√≥n:** Mantener `LOG_DIA_X.md` diarios + tabla de experimentos

### ‚ùå Error #18: No documentar hiperpar√°metros

**Problema:** Reportar "us√© Adam optimizer" sin especificar learning rate  
**Impacto:** Experimento no reproducible  
**Soluci√≥n:** Documentar TODOS los hiperpar√°metros en tabla de la tesis

### ‚ùå Error #19: No explicar decisiones t√©cnicas

**Problema:** Decir "us√© EfficientNet" sin justificar por qu√©  
**Impacto:** Jurado pregunta, no sabes responder  
**Soluci√≥n:** Para cada decisi√≥n, tener 2-3 razones t√©cnicas documentadas

### ‚ùå Error #20: No mantener c√≥digo limpio

**Problema:** 10 archivos `test.py`, `test2.py`, `test_final.py`, `test_final_v2.py`  
**Impacto:** C√≥digo incomprensible, no reproducible  
**Soluci√≥n:** Nombres descriptivos, estructura clara, comentarios en c√≥digo

---

## üö´ CATEGOR√çA 6: PRESENTACI√ìN

### ‚ùå Error #21: Slides con mucho texto

**Problema:** Poner p√°rrafos completos en presentaci√≥n de defensa  
**Impacto:** Audiencia no lee, t√∫ lees slides = mala presentaci√≥n  
**Soluci√≥n:** M√°ximo 5 bullets por slide, usar visuales

### ‚ùå Error #22: Demo sin preparar

**Problema:** Mostrar demo en vivo sin haberla probado 5+ veces  
**Impacto:** Falla durante defensa = p√©rdida de credibilidad  
**Soluci√≥n:** 10 ensayos de demo, tener video backup

### ‚ùå Error #23: No anticipar preguntas

**Problema:** Defender sin preparar respuestas a preguntas obvias  
**Impacto:** Nervios, respuestas vagas  
**Soluci√≥n:** Lista de 20 preguntas probables con respuestas preparadas

---

## ‚úÖ CHECKLIST DE PREVENCI√ìN

**Antes de cada sesi√≥n:**

- [ ] Verificar que `config.py` est√° actualizado
- [ ] Confirmar que rutas en config existen
- [ ] Comprobar semilla aleatoria est√° fija
- [ ] Revisar que test set no se contamina

**Durante entrenamiento:**

- [ ] Monitorear val_loss cada epoch
- [ ] Guardar checkpoints peri√≥dicamente
- [ ] Anotar hiperpar√°metros en log
- [ ] Verificar uso de GPU (nvidia-smi)

**Despu√©s de experimento:**

- [ ] Documentar resultados en LOG
- [ ] Guardar modelo con nombre descriptivo
- [ ] Generar gr√°ficas de loss/accuracy
- [ ] Anotar observaciones y siguientes pasos

**Antes de defensa:**

- [ ] Ensayar presentaci√≥n 5+ veces
- [ ] Probar demo 10+ veces
- [ ] Preparar respuestas a 20 preguntas
- [ ] Tener backup de todo en USB

---

## üéØ REGLA DE ORO

> **"Si no est√° documentado, no existe."**

- Resultados sin logs = no replicables
- C√≥digo sin comentarios = incomprensible en 1 semana
- Decisiones sin justificaci√≥n = vulnerables en defensa

**Invierte 10 minutos en documentar, ahorra 10 horas en confusi√≥n.**

---

_Mant√©n este archivo abierto durante todo el proyecto. Rev√≠salo antes de cada sesi√≥n._

**Actualizado:** 7 de octubre, 2025
